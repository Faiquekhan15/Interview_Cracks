1. Load balancing is a technique used to distribute a load across multiple devices, servers for example. Often it is configured to distribute the load evenly. Which of the following are true? 
Pick ONE OR MORE options 
a) Starving occurs when some resource, e.g. a server, does not process any requests, but others do. 
b) Any reasonable system has only one load balancer. 
c) A health check is a procedure that checks if the load is indeed balanced across resources. 
d) If a load balancer is not a bottleneck, then using it increases the throughput of the system. 
e) Sometimes it makes sense to have a load balancer that distributes the load in an uneven manner. 

**Answer is a,c,d,e


2. Data Partitioning 
In data partitioning, a large dataset is divided into smaller pieces. Which of the following are true? 
Pick ONE OR MORE options 
a) There is a users database that stores many attributes for each user. It is partitioned so that one partition gets names  and emails, another partition receives avatars and addresses and so on. This is called vertical partitioning. 
b)  If you have a collection of users with a lot of attributes and you decide to partition the data so that each partition receives just a subset of users with all their attributes, this is called horizontal partitioning. 
c)  Vertical and horizontal partitioning cannot be combined. 
d) Round-robin partitioning is a partitioning strategy that is especially good when the number of partitions changes over time.

 **Answer is a,b,d


5. Caching 2 
Caching is used to serve stored data more efficiently. It is commonly used, particularly in large scale distributed systems, to allow the most frequently accessed information to be available at a lower cost in time or resources. Since cache capacity is limited, strategies are employed to determine what is in the cache and when it should be replaced. These are referred to as eviction policies and replacement policies. Which of the following are true? 
Pick ONE OR MORE options 
a) A cache hit is a situation when the cache becomes full. 
b)  LRU and MRU are eviction policies that respectively discard least recently used and most recently used elements from El the cache to make space for other elements. In applications like social networks with feed, LRU, in general, performs significantly better than MRU. 
c) If the future is known, it is possible to design an eviction policy that is optimal. 
d) The data in a cache is always consistent with the changes made to it. Any time it is requested, the most recent version is returned. 

 **Answer is b,c
